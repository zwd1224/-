{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from utils.features.prepare_for_training import prepare_for_training\n",
    "class LogisticRegression:\n",
    "    def __init__(self, data, labels, polynomial_degree=0, sinusoid_degree=0, normalize_data=False):\n",
    "        \"\"\"\n",
    "        1.对数据进行预处理操作\n",
    "        2.先得到所有的特征个数\n",
    "        3.初始化参数矩阵\n",
    "        \"\"\"\n",
    "        (data_processed,\n",
    "         features_mean,\n",
    "         features_deviation) = prepare_for_training(data, polynomial_degree, sinusoid_degree, normalize_data=False)\n",
    " \n",
    "        self.data = data_processed\n",
    "        self.labels = labels\n",
    "        self.unique_labels = np.unique(labels)  # 去重\n",
    "        self.features_mean = features_mean\n",
    "        self.features_deviation = features_deviation\n",
    "        self.polynomial_degree = polynomial_degree\n",
    "        self.sinusoid_degree = sinusoid_degree\n",
    "        self.normalize_data = normalize_data\n",
    "\n",
    "        # 特征个数\n",
    "        num_features = self.data.shape[1]\n",
    "        # 标签个数\n",
    "        num_unique_labels = np.unique(labels).shape[0]\n",
    "        self.theta = np.zeros((num_unique_labels, num_features))\n",
    " \n",
    "    def train(self, max_iterations=1000):\n",
    "        cost_histories = []\n",
    "        num_features = self.data.shape[1] \n",
    "        for label_index, unique_label in enumerate(self.unique_labels): #把每个标签都训练\n",
    "            current_initial_theta = np.copy(self.theta[label_index].reshape(num_features, 1)) #当前标签的参数\n",
    "            current_lables = (self.labels == unique_label).astype(float) #当前特征的对应的标签\n",
    "            (current_theta, cost_history) = LogisticRegression.gradient_descent(self.data, current_lables,\n",
    "                                                                                current_initial_theta, max_iterations) #执行梯度下降\n",
    "            self.theta[label_index] = current_theta.T #更新\n",
    "            cost_histories.append(cost_history)\n",
    " \n",
    "        return self.theta, cost_histories\n",
    "    @staticmethod\n",
    "    def gradient_descent(data, labels, current_initial_theta, max_iterations):\n",
    "        cost_history = []\n",
    "        num_features = data.shape[1]        # flatten():将多维数组转换为一维数组：flatten() 方法将一个多维数组“压平”成一个一维数组。\n",
    "        \n",
    "        result = minimize(\n",
    "            # 要优化的目标： 优化函数 损失函数\n",
    "            lambda current_theta: LogisticRegression.cost_function(data, labels,\n",
    "                                                                   current_theta.reshape(num_features, 1)), \n",
    "            # 初始化的权重参数\n",
    "            current_initial_theta.flatten(),\n",
    "            # 选择优化策略\n",
    "            method='CG',#共轭梯度\n",
    "\n",
    "            # 梯度下降迭代计算公式\n",
    "            jac=lambda current_theta: LogisticRegression.gradient_step(data, labels,\n",
    "                                                                       current_theta.reshape(num_features, 1)),\n",
    "            # 记录结果\n",
    "            callback=lambda current_theta: cost_history.append(\n",
    "                LogisticRegression.cost_function(data, labels, current_theta.reshape((num_features, 1)))),\n",
    "            # 迭代次数\n",
    "            options={'maxiter': max_iterations}\n",
    "        )\n",
    "        optimized_theta = result.x.reshape(num_features, 1)\n",
    "        return optimized_theta, cost_history\n",
    " \n",
    "    #计算损失\n",
    "    @staticmethod\n",
    "    def cost_function(data, labels, theat): \n",
    "        num_examples = data.shape[0]\n",
    "        predictions = LogisticRegression.hypothesis(data, theat)\n",
    "        # y1 * log( h(x1) )\n",
    "        cost1 = np.dot(labels[labels == 1].T, np.log(predictions[labels == 1])) \n",
    "        # (1-y0) * log( 1- h(x0) )\n",
    "        cost0 = np.dot(1 - labels[labels == 0].T, np.log(1 - predictions[labels == 0]))\n",
    "        cost = (-1 / num_examples) * (cost1 + cost0)\n",
    "        return cost\n",
    " \n",
    "    @staticmethod\n",
    "    def hypothesis(data, theat):\n",
    "        return sigmoid(np.dot(data, theat))\n",
    " \n",
    "    @staticmethod #计算梯度值\n",
    "    def gradient_step(data, labels, theta):\n",
    "        num_examples = labels.shape[0]\n",
    "        predictions = LogisticRegression.hypothesis(data, theta)\n",
    "        label_diff = predictions - labels\n",
    "        gradients = (1 / num_examples) * np.dot(data.T, label_diff)\n",
    " \n",
    "        return gradients.T.flatten()\n",
    " \n",
    "    def predict(self, data):\n",
    "        num_examples = data.shape[0]\n",
    "        data_processed = prepare_for_training(data, self.polynomial_degree, self.sinusoid_degree, self.normalize_data)[0]\n",
    "        prob = LogisticRegression.hypothesis(data_processed, self.theta.T)\n",
    "        max_prob_index = np.argmax(prob, axis=1) #把概率最大的那个值拿出来\n",
    "        class_prediction = np.empty(max_prob_index.shape, dtype=object)\n",
    "        for index, label in enumerate(self.unique_labels):\n",
    "            class_prediction[max_prob_index == index] = label\n",
    "        return class_prediction.reshape((num_examples, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('microchips-tests.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
